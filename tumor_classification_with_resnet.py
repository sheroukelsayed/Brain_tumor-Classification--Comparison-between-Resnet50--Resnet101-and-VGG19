# -*- coding: utf-8 -*-
"""Tumor classification with Resnet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hM71OHiYhG7eoQWk-kpFpsovVhL9ZgDy
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
from sklearn.utils import shuffle

train_df = pd.read_csv('/content/drive// My Drive/CNN folder/Tumor/tumor/training_data.csv')

# Shuffle the DataFrame
train_df_shuffled = shuffle(train_df, random_state=42)  # You can set a specific random_state for reproducibility

train_df_shuffled.head(5)

test_df = pd.read_csv('/content/drive// My Drive/CNN folder/Tumor/tumor/testing_data.csv')

import cv2
import numpy as np

import matplotlib as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.applications import ResNet50
from tensorflow.keras import layers, models
from tensorflow.keras.utils import to_categorical

X=[]
Y=[]

for index, row in train_df_shuffled.iterrows():

    image = cv2.imread(row['image_path'])


    # Check if the image is None (indicating failure to read)
    if image is None:
        print(f"Error reading image: {row['image_path']}")
        break;
    else:
    # Resize the image
      image = cv2.resize(image, (224, 224))
      print(image.shape)
      label = row['label']
      X.append(image)
      Y.append(label)

X_test=[]
Y_test=[]
for index, row in test_df.iterrows():

    image = cv2.imread(row['image_path'])


    # Check if the image is None (indicating failure to read)
    if image is None:
        print(f"Error reading image: {row['image_path']}")
        break;
    else:
    # Resize the image
      image = cv2.resize(image, (224, 224))
      print(image.shape)
      label = row['label']
      X_test.append(image)
      Y_test.append(label)

# Convert lists to numpy arrays
X = np.array(X)
y = np.array(Y)

# Convert labels to numerical format
y_categorical =to_categorical(train_df_shuffled['label'])


# Split the dataset into training and testing sets
X_train, X_valid, y_train, y_valid = train_test_split(X, y_categorical, test_size=0.2, random_state=42)

from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
from tensorflow.keras.applications import ResNet101

from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.models import Model

# Load the ResNet101 model pre-trained on ImageNet data
base_model = ResNet101(weights='imagenet', include_top=False, input_shape=(224, 224, 3))


# Freeze the pre-trained layers
for layer in base_model.layers:
    layer.trainable = False

# Add a custom classifier on top of the VGG16 model
x = GlobalAveragePooling2D()(base_model.output)
x = Dense(128, activation='relu')(x)
output = Dense(4, activation='softmax')(x)  # Assuming 2 classes (Stop and Non-Stop)

# Create the final model
Resnet101_freeze = Model(inputs=base_model.input, outputs=output)

# Compile the model
Resnet101_freeze.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
Resnet101_freeze.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=[X_valid, y_valid])

Resnet101_freeze.save('/content/drive// My Drive/CNN folder/Tumor/tumor/resnet101Model.h5')

# Load the ResNet50 model pre-trained on ImageNet data
base_model = ResNet101(weights='imagenet', include_top=False, input_shape=(224, 224, 3))


# Freeze the pre-trained layers
for layer in base_model.layers:
    layer.trainable = False

# Add a custom classifier on top of the VGG16 model
x = GlobalAveragePooling2D()(base_model.output)
x = Dense(128, activation='relu')(x)
output = Dense(4, activation='softmax')(x)  # Assuming 2 classes (Stop and Non-Stop)

# Create the final model
Resnet50_freeze = Model(inputs=base_model.input, outputs=output)

# Compile the model
Resnet50_freeze.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
Resnet50_freeze.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=[X_valid, y_valid])

Resnet50_freeze.save('/content/drive// My Drive/CNN folder/Tumor/tumor/resnet50Model.h5')

#Load the VGG19 model pre-trained on ImageNet data
base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze the pre-trained layers
for layer in base_model.layers:
    layer.trainable = False

# Add a custom classifier on top of the VGG19 model
x = GlobalAveragePooling2D()(base_model.output)
x = Dense(128, activation='relu')(x)
output = Dense(4, activation='softmax')(x)  # Assuming 4 classes

# Create the final model
vgg19_freeze = Model(inputs=base_model.input, outputs=output)

# Compile the model
vgg19_freeze.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
vgg19_freeze.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_valid, y_valid))

vgg19_freeze.save('/content/drive// My Drive/CNN folder/Tumor/tumor/resnet50Model.h5')

# Evaluate on validation data
resnet50_val_preds = Resnet50_freeze.predict(X_valid)
resnet101_val_preds = Resnet101_freeze.predict(X_valid)
vgg19_val_preds = vgg19_freeze.predict(X_valid)

from sklearn.metrics import accuracy_score, f1_score

resnet50_val_accuracy = accuracy_score(np.argmax(y_valid, axis=1), np.argmax(resnet50_val_preds, axis=1))
resnet101_val_accuracy = accuracy_score(np.argmax(y_valid, axis=1), np.argmax(resnet101_val_preds, axis=1))
vgg19_val_accuracy = accuracy_score(np.argmax(y_valid, axis=1), np.argmax(vgg19_val_preds, axis=1))

resnet50_val_f1= f1_score(np.argmax(y_valid, axis=1), np.argmax(resnet50_val_preds, axis=1), average='weighted')
resnet101_val_f1 = f1_score(np.argmax(y_valid, axis=1), np.argmax(resnet101_val_preds, axis=1), average='weighted')
vgg19_val_f1 = f1_score(np.argmax(y_valid, axis=1), np.argmax(vgg19_val_preds, axis=1), average='weighted')

# Repeat similar steps for test data

# Create a bar chart
labels = ['ResNet50', 'ResNet101', 'VGG19']
val_accuracies = [resnet50_val_accuracy, resnet101_val_accuracy, vgg19_val_accuracy]
val_f1_scores = [resnet50_val_f1, resnet101_val_f1, vgg19_val_f1]



fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))

ax1.bar(labels, val_accuracies, color=['blue', 'green', 'orange'])
ax1.set_title('Validation Accuracy')

ax2.bar(labels, val_f1_scores, color=['blue', 'green', 'orange'])
ax2.set_title('Validation F1-Score')

plt.tight_layout()
plt.show()

# Evaluate on validation data
resnet50_test_preds = Resnet50_freeze.predict(X_test)
resnet101_test_preds = Resnet101_freeze.predict(X_test)
vgg19_test_preds = vgg19_freeze.predict(X_test)

resnet50_test_accuracy = accuracy_score(Y_test, np.argmax(resnet50_test_preds, axis=1))
resnet101_test_accuracy = accuracy_score(Y_test, np.argmax(resnet101_test_preds, axis=1))
vgg19_test_accuracy = accuracy_score(Y_test, np.argmax(vgg19_test_preds, axis=1))

resnet50_test_f1 = f1_score(Y_test, np.argmax(resnet50_test_preds, axis=1), average='weighted')
resnet101_test_f1 = f1_score(Y_test, np.argmax(resnet101_test_preds, axis=1), average='weighted')
vgg19_test_f1 = f1_score(Y_test, np.argmax(vgg19_test_preds, axis=1), average='weighted')

# Repeat similar steps for test data

# Create a bar chart
labels = ['ResNet50', 'ResNet101', 'VGG19']
test_accuracies = [resnet50_test_accuracy, resnet101_test_accuracy, vgg19_test_accuracy]
test_f1_scores = [resnet50_test_f1, resnet101_test_f1, vgg19_test_f1]



fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))

ax1.bar(labels, test_accuracies, color=['blue', 'green', 'orange'])
ax1.set_title('Test Accuracy')

ax2.bar(labels, test_f1_scores, color=['blue', 'green', 'orange'])
ax2.set_title('Test F1-Score')
# Set the overall title for the entire figure
fig.suptitle('Comparison of Model Performance on test data', fontsize=16)
plt.tight_layout()
plt.show()